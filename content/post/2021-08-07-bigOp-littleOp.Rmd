---
title: $O_p$(Big-Op)와 $o_p$(Little-Op)
date: '2021-08-07'
coverImage: 
coverMeta: out
metaAlignment: center
categories:
  - Statistics
tags:
  - big O
  - little o
  - asymptotic
  - convergence rate
---

Big-O와 little-O를 사용한 점근표기법(asymptotic notation)은 수학에서 rate of convergence를 나타내고 위해 사용되며, 또한 알고리즘의 시간복잡도를 나타낼 때에도 사용하는데요.
이 notation을 stochastic sequence에 적용한 것이 $O_p$(Big-Op)와 $o_p$(Little-Op)입니다.


## $O_p$ (Big-Op)
$O_p$ (Big-Op)는 *stochastic boundness* 또는 *bounded in probability*의 의미를 나타내며, 이에 대한 정의는 다음과 같습니다.

::: {.definition name="$O_p$ (Big-Op)"}
*For a set of random variable $X_n$ and a corresponding set of constants $a_n$, $X_n = O_p(a_n)$ if and only if $\forall \epsilon > 0, ~ \exists M, N > 0$ such that 
$$
P\left(\left| \frac{X_n}{a_n} \right| > M \right) < \epsilon, ~ \forall n > N.
$$*
:::


## $o_p$ (Little-Op)
$o_p$ (Little-Op)는 수리통계학에서 접하게 되는 *convergence in probability(확률수렴)*을 의미하며, 정의는 다음과 같습니다.

::: {.definition name="$o_p$ (Little-Op)"}
*For a set of random variable $X_n$ and a corresponding set of constants $a_n$, $X_n = o_p(a_n)$ if and only if
$$
\lim_{n \rightarrow \infty} P\left(\left| \frac{X_n}{a_n} \right| \ge \epsilon \right) = 0, ~ \forall \epsilon > 0.
$$*
:::

다시 말해, $X_n = o_p(a_n)$의 필요충분조건은 $\frac{X_n}{a_n} \overset{p}{\rightarrow} 0$ 입니다.



## Consistency using $O_p$ notation
보통 논문에서는 어떤 추정량(estimator)의 consistency를 $o_p$가 아닌 $O_p$로 나타내기도 하는데, 다음 논문의 예를 통해 왜 그런 방식이 성립하는지 알아보겠습니다.

> Yao, F., Müller, H. G., & Wang, J. L. (2005). Functional data analysis for sparse longitudinal data. *Journal of the American statistical association*, 100(470), 577-590.

논문의 Theorem 2 - equation (15)에는 $k$th eigenvalue $\lambda_k$에 대한 추정량 $\hat\lambda_k$의 consistency를 다음과 같이 $O_p$ 기호를 사용하여 나타내는데요.
$$
|\hat\lambda_k - \lambda_k| = O_p\left( \frac{1}{\sqrt{n}h^2_G} \right)
$$

이는 $O_p$의 정의를 사용하여 나타내보면 쉽게 이해할 수 있습니다.
$$
\begin{aligned}
|\hat\lambda_k - \lambda_k| = O_p\left( \frac{1}{\sqrt{n}h^2_G} \right) &\Leftrightarrow P\left(\left\lvert \frac{|\hat\lambda_k - \lambda_k|}{1/\sqrt{n}h^2_G} \right\rvert > M \right) < \epsilon \\
&\Leftrightarrow P\left(|\hat\lambda_k - \lambda_k| > \frac{M}{\sqrt{n}h^2_G} \right) < \epsilon
\end{aligned}
$$
여기서 $h_G < \infty$인 상수이기 때문에 $n$에 대한 극한을 취하고, $M/\sqrt{n}h^2_G$을 임의의 작은 실수 $\epsilon^*$로 대체하게 되면 이는 convergence in probability의 정의를 만족하며, $\hat\lambda_k$아 $\lambda_k$의 consistent estimator임을 의미하게 됩니다.
다시 말해, $O_p$ 기호로도 consistency를 표현할 수 있는 것이죠.

<br>

## Reference
- <https://bookdown.org/ts_robinson1994/10_fundamental_theorems_for_econometrics/big-op-and-little-op.html>
- <https://en.wikipedia.org/wiki/Big_O_in_probability_notation>
- Yao, F., Müller, H. G., & Wang, J. L. (2005). Functional data analysis for sparse longitudinal data. *Journal of the American statistical association*, 100(470), 577-590.