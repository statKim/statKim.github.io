---
categories:
  - statistics
  - FDA
coverImage: 
coverMeta: out
date: "2020-01-20"
metaAlignment: center
tags:
  - FPCA
  - FDA
  - sparse
  - statistics
title: Functional Principal Component Analysis
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<ul>
<li>Functional Principal Component Anlaysis (FPCA)란 이름 그대로 functional data에 적용하는 PCA 방법</li>
<li>일반적으로 잘 알려져 있는 multivariate PCA는 <span class="math inline">\(p\)</span>개의 변수를 <span class="math inline">\(q(\ll p)\)</span>개의 변수로 차원축소(dimension reduction)하는 방법으로 각 변수들이 uncorrelated되기 때문에 회귀분석(regression)에서 흔히 발생하는 다중공선성(multicolinearity)을 해결할 수 있는 대표적인 방법임</li>
</ul>
<p><br></p>
<div id="functional-data" class="section level2">
<h2>Functional data??</h2>
<ul>
<li><p>Functional data란 여러 개체가 각각 시간이나 위치 등에 따라 관측된 형태를 보이는 데이터로 보통 종단자료(longitudinal data) or 시계열(time series) 데이터를 다른 관점에서 본 경우입니다.</p></li>
<li><p>시간에 따라 관측된 데이터를 연속(continuous)인 곡선(curve) 형태로 보고 분석하는 데이터 형태입니다.</p></li>
<li><p>Smootheness를 가정하고 있기 때문에 smoothing 방법이 필요하게 됩니다.</p></li>
<li><p>B-spline, wavelet basis 등의 basis function을 사용하여 smoothing하게 되고 basis 개수에 따라 smoothing 정도가 결정됨</p></li>
<li><p>하지만 형태가 복잡해지는 경우, smooth basis function의 개수가 많아져 차원이 커지는 문제 발생 <span class="math inline">\(\Rightarrow\)</span> <strong>차원축소 방법이 필요!!</strong></p>
<p><img src="http://www.psych.mcgill.ca/misc/fda/images/examples/ex-weather-afig1.jpg"></p></li>
</ul>
<p><em>캐나다 35개 지점의 월별 기온 데이터(출처: Functional Data Analysis Website)</em></p>
<p><br></p>
</div>
<div id="functional-pca" class="section level2">
<h2>Functional PCA</h2>
<ul>
<li><p>Functional PCA도 역시 dimension reduction 방법으로 basis fuction의 dimension을 줄여주는 방법</p></li>
<li><p>PCA와 마찬가지로 covariance matrix를 고유값 분해(eigenvalue decomposition)를 통해 구하게 됨</p></li>
<li><p>Smoothness를 가정하기 때문에 inner product가 새롭게 정의됨
<span class="math display">\[
  \langle x, y \rangle = \int x(t)y(t)dt
  \]</span></p></li>
</ul>
<p><br></p>
</div>
<div id="how-to-solve-functional-pca" class="section level2">
<h2>How to solve Functional PCA??</h2>
<ul>
<li>PCA와 마찬가지로 데이터의 평균(mean)을 빼어 centering한 후에 계산된 covariance matrix를 고유값 분해(eigenvalue decomposition)하여 구할 수 있음</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Define the covariance function</p>
<p><span class="math display">\[
  v(s,t) = \frac{1}{N}\sum_{i=1}^N x_i(s)x_i(t) 
 \]</span>
where <span class="math inline">\(x_i(t)\)</span> is centerized.</p></li>
<li><p>Each of PC weight functions(or loadings) satisfies follow eigenequation</p>
<p><span class="math display">\[
 \int v(s,t)\xi(t)dt = \rho \xi(s)
 \]</span>
or another form using covariance overator <span class="math inline">\(V\)</span>,</p>
<p><span class="math display">\[
 V\xi = \rho \xi
 \]</span>
where $ V= v(,t)(t)dt $ and <span class="math inline">\(\xi\)</span> is an eigenfunction.</p></li>
<li><p>Apply eigenvalue decomposition to above eigenequation</p>
<ul>
<li>The eigenfunction <span class="math inline">\(\xi\)</span> be the PC weight function.</li>
</ul></li>
</ol>
<p><br></p>
</div>
<div id="multivariate-pca-vs-functional-pca" class="section level2">
<h2>Multivariate PCA vs Functional PCA</h2>
<ul>
<li>구할 수 있는 eigen pairs의 개수가 다름
<ul>
<li>Multivariate : # of eigen pairs = <span class="math inline">\(p\)</span> (raw data의 dimension)</li>
<li>Functional : # of eigen pairs = <span class="math inline">\(\infty\)</span> (<span class="math inline">\(\because\)</span> smootheness)</li>
</ul></li>
<li>Smoothness 가정
<ul>
<li>이 가정으로 인해 multivariate PCA에서 <span class="math inline">\(\sum\)</span>으로 구하게 되는 inner product가 functional PCA에서는 <span class="math inline">\(\int\)</span>로 구하게 됨</li>
</ul></li>
</ul>
<p><br></p>
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<ul>
<li>Ramsay. &amp; Silverman. (2005), <strong>Functional Data Analysis 2nd edition.</strong> Springer</li>
<li><a href="http://www.psych.mcgill.ca/misc/fda/index.html">Functional Data Analysis Website</a></li>
</ul>
</div>
